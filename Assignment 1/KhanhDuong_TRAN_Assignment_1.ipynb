{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center> Assignment 01: Basic to Complex Image classification <br> <br> <small>14 december 2023</small> </center>\n",
    "\n",
    "The goal of this assignment is :\n",
    "\n",
    "    - Classify digits and dog breed from two kaggle datasets.\n",
    "    - Try to implement a linear and a non-linear model.\n",
    "    - Compare the accuracies between models in each task.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Lambda, Dropout, Input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:59:17.052044Z",
     "start_time": "2023-12-14T16:59:17.051725Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Digit regconizer\n",
    "\n",
    "**Task:** Classify grey-scale hand-written digits from 0 to 9. The images are 28 x 28 pixels. The training dataset is in csv format, has 42000 records with 784 features from pixel0 to pixel783.\n",
    "\n",
    "The strategy is to implement the linear model of K-Nearest Neighbors while the non-linear model is a CNN layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "# Load both train and test sets\n",
    "train_master = pd.read_csv(\"../Assignment 1/digit-recognizer/train.csv\")\n",
    "test_master = pd.read_csv(\"../Assignment 1/digit-recognizer/test.csv\")\n",
    "\n",
    "train = train_master.copy().drop(\"label\", axis=1)\n",
    "label = train_master.label\n",
    "test = test_master.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:11:44.721794Z",
     "start_time": "2023-12-14T16:11:42.955041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(label.shape)\n",
    "print(test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:11:44.725179Z",
     "start_time": "2023-12-14T16:11:44.723432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 784 columns</p>\n</div>"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect a few rows\n",
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:11:44.738109Z",
     "start_time": "2023-12-14T16:11:44.733692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0       0       0       0       0       0       0       0       0       0   \n1       0       0       0       0       0       0       0       0       0   \n2       0       0       0       0       0       0       0       0       0   \n3       0       0       0       0       0       0       0       0       0   \n4       0       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 784 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 784 columns</p>\n</div>"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect test set to be predicted later\n",
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:11:44.773559Z",
     "start_time": "2023-12-14T16:11:44.741376Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784)\n",
      "(8400, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:11:45.066830Z",
     "start_time": "2023-12-14T16:11:44.747709Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Traditional Machine learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=1)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K as 1 is enough\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:11:45.248730Z",
     "start_time": "2023-12-14T16:11:44.939191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "array([8, 1, 9, ..., 3, 0, 9])"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "y_pred = knn.predict(X_test.to_numpy())\n",
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:11:51.723297Z",
     "start_time": "2023-12-14T16:11:45.106576Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       816\n",
      "           1       0.97      1.00      0.98       909\n",
      "           2       0.98      0.95      0.97       846\n",
      "           3       0.97      0.96      0.96       937\n",
      "           4       0.98      0.97      0.97       839\n",
      "           5       0.96      0.96      0.96       702\n",
      "           6       0.98      0.99      0.98       785\n",
      "           7       0.96      0.97      0.96       893\n",
      "           8       0.98      0.94      0.96       835\n",
      "           9       0.94      0.96      0.95       838\n",
      "\n",
      "    accuracy                           0.97      8400\n",
      "   macro avg       0.97      0.97      0.97      8400\n",
      "weighted avg       0.97      0.97      0.97      8400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:11:51.740283Z",
     "start_time": "2023-12-14T16:11:51.724237Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Comment: The KNN model performed quite well with an accuracy of 97%. This shalls be the baseline to compare the CNN model with."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "test_predict = knn.predict(test.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:10.701326Z",
     "start_time": "2023-12-14T16:11:51.741543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit is 4\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test.iloc[1200].values.reshape(28, 28), cmap=\"gray\")\n",
    "print(f'The digit is {test_predict[1200]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:11.018323Z",
     "start_time": "2023-12-14T16:12:10.709828Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit is 1\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test.iloc[5000].values.reshape(28, 28), cmap=\"gray\")\n",
    "print(f'The digit is {test_predict[5000]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:11.124579Z",
     "start_time": "2023-12-14T16:12:11.020883Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> We can clearly see the linear model is able to detect digits quite well when we try a couple of examples."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processing data\n",
    "\n",
    "In building the CNN, it is a good idea to normalize the data and convert the label with one hot encoder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "X_train_norm = X_train / 255\n",
    "X_test_norm = X_test / 255"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:11.145953Z",
     "start_time": "2023-12-14T16:12:11.082019Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "\n",
    "Y_train = to_categorical(y_train, n_classes)\n",
    "Y_test = to_categorical(y_test, n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:11.146534Z",
     "start_time": "2023-12-14T16:12:11.135286Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_38 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 200)               20200     \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100710 (393.40 KB)\n",
      "Trainable params: 100710 (393.40 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:11.215250Z",
     "start_time": "2023-12-14T16:12:11.155952Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "525/525 [==============================] - 1s 1ms/step - loss: 0.3462 - accuracy: 0.9021 - val_loss: 0.1821 - val_accuracy: 0.9457\n",
      "Epoch 2/20\n",
      "525/525 [==============================] - 1s 1ms/step - loss: 0.1465 - accuracy: 0.9557 - val_loss: 0.1475 - val_accuracy: 0.9567\n",
      "Epoch 3/20\n",
      "525/525 [==============================] - 0s 897us/step - loss: 0.1000 - accuracy: 0.9699 - val_loss: 0.1178 - val_accuracy: 0.9632\n",
      "Epoch 4/20\n",
      "525/525 [==============================] - 0s 844us/step - loss: 0.0761 - accuracy: 0.9768 - val_loss: 0.1131 - val_accuracy: 0.9630\n",
      "Epoch 5/20\n",
      "525/525 [==============================] - 0s 851us/step - loss: 0.0572 - accuracy: 0.9823 - val_loss: 0.1055 - val_accuracy: 0.9673\n",
      "Epoch 6/20\n",
      "525/525 [==============================] - 0s 863us/step - loss: 0.0459 - accuracy: 0.9849 - val_loss: 0.1047 - val_accuracy: 0.9681\n",
      "Epoch 7/20\n",
      "525/525 [==============================] - 0s 853us/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 0.1019 - val_accuracy: 0.9698\n",
      "Epoch 8/20\n",
      "525/525 [==============================] - 0s 851us/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.1062 - val_accuracy: 0.9705\n",
      "Epoch 9/20\n",
      "525/525 [==============================] - 0s 803us/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.1081 - val_accuracy: 0.9708\n",
      "Epoch 10/20\n",
      "525/525 [==============================] - 0s 829us/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 0.1187 - val_accuracy: 0.9660\n",
      "Epoch 11/20\n",
      "525/525 [==============================] - 0s 813us/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.1201 - val_accuracy: 0.9694\n",
      "Epoch 12/20\n",
      "525/525 [==============================] - 0s 818us/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 0.1131 - val_accuracy: 0.9705\n",
      "Epoch 13/20\n",
      "525/525 [==============================] - 0s 853us/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.1235 - val_accuracy: 0.9696\n",
      "Epoch 14/20\n",
      "525/525 [==============================] - 0s 936us/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.1197 - val_accuracy: 0.9713\n",
      "Epoch 15/20\n",
      "525/525 [==============================] - 0s 925us/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.1277 - val_accuracy: 0.9715\n",
      "Epoch 16/20\n",
      "525/525 [==============================] - 0s 848us/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1827 - val_accuracy: 0.9652\n",
      "Epoch 17/20\n",
      "525/525 [==============================] - 0s 828us/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.1415 - val_accuracy: 0.9711\n",
      "Epoch 18/20\n",
      "525/525 [==============================] - 0s 884us/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.1360 - val_accuracy: 0.9720\n",
      "Epoch 19/20\n",
      "525/525 [==============================] - 0s 885us/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.1535 - val_accuracy: 0.9694\n",
      "Epoch 20/20\n",
      "525/525 [==============================] - 0s 874us/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.1606 - val_accuracy: 0.9693\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x28a007ed0>"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "model.fit(X_train_norm, Y_train, batch_size=64, epochs=20, validation_data=(X_test_norm, Y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:20.844279Z",
     "start_time": "2023-12-14T16:12:11.218052Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Comment:\n",
    "> So I tried to build a very simple CNN with 3 layers, an input then a calculation and finally an output layer with the first two have \"relu\" activation while the last has the \"softmax\".\n",
    "> After fitting the model, the accuracy of the CNN is closed to the accuracy of the KNN, around 97% depending on the epochs.\n",
    "> What I can say is: the digits classification task is rather simple and two models performed nearly similar to each others. However, in the next task with identify the dog breed from the image with larger amount of pixels. We will see how the CNN is better."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 0s 317us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_cnn = model.predict(test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:21.342561Z",
     "start_time": "2023-12-14T16:12:20.845962Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit is 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the CNN model\n",
    "plt.imshow(test.iloc[1900].values.reshape(28, 28), cmap=\"gray\")\n",
    "print(f'The digit is {np.argmax(y_pred_cnn[1900])}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:21.401088Z",
     "start_time": "2023-12-14T16:12:21.351615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit is 3\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test.iloc[6900].values.reshape(28, 28), cmap=\"gray\")\n",
    "print(f'The digit is {np.argmax(y_pred_cnn[6900])}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:21.459843Z",
     "start_time": "2023-12-14T16:12:21.405224Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dog breed\n",
    "\n",
    "**Task:** Classify different dog breeds from images. The images are in different pixels. The training dataset is a number of dog images with a csv file labelling which breed, there are 10222 images for training.\n",
    "\n",
    "The same strategy is implemented with one linear model of K-Nearest Neighbors while the non-linear model is a CNN layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "# Setting some variables\n",
    "train_path = \"../Assignment 1/dog-breed-identification/train/\"\n",
    "labels_path = \"../Assignment 1/dog-breed-identification/labels.csv\"\n",
    "img_size = [64, 64, 3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:21.460085Z",
     "start_time": "2023-12-14T16:12:21.455243Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(63132) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in the train folder is:    10222\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(63137) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of images in the test folder is:    10357\r\n"
     ]
    }
   ],
   "source": [
    "# Print the number of images in folders\n",
    "!echo \"The number of images in the train folder is: $(ls dog-breed-identification/train/*.jpg | wc -l)\"\n",
    "!echo \"The number of images in the test folder is: $(ls dog-breed-identification/test/*.jpg | wc -l)\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:22.304387Z",
     "start_time": "2023-12-14T16:12:21.461763Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "labels_master = pd.read_csv(\"../Assignment 1/dog-breed-identification/labels.csv\")\n",
    "labels = labels_master.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:22.320723Z",
     "start_time": "2023-12-14T16:12:22.306701Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "10222"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:22.323139Z",
     "start_time": "2023-12-14T16:12:22.321422Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 id             breed\n0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n2  001cdf01b096e06d78e9e5112d419397          pekinese\n3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>breed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n      <td>boston_bull</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n      <td>dingo</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>001cdf01b096e06d78e9e5112d419397</td>\n      <td>pekinese</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n      <td>bluetick</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n      <td>golden_retriever</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:22.344134Z",
     "start_time": "2023-12-14T16:12:22.325583Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "              breed                                               path\n0       boston_bull  ../Assignment 1/dog-breed-identification/train...\n1             dingo  ../Assignment 1/dog-breed-identification/train...\n2          pekinese  ../Assignment 1/dog-breed-identification/train...\n3          bluetick  ../Assignment 1/dog-breed-identification/train...\n4  golden_retriever  ../Assignment 1/dog-breed-identification/train...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>breed</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>boston_bull</td>\n      <td>../Assignment 1/dog-breed-identification/train...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dingo</td>\n      <td>../Assignment 1/dog-breed-identification/train...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pekinese</td>\n      <td>../Assignment 1/dog-breed-identification/train...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bluetick</td>\n      <td>../Assignment 1/dog-breed-identification/train...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>golden_retriever</td>\n      <td>../Assignment 1/dog-breed-identification/train...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the path to the dataframe for later use\n",
    "labels[\"path\"] = train_path + labels.id + \".jpg\"\n",
    "labels.drop(\"id\", axis=1, inplace=True)\n",
    "labels.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:22.344376Z",
     "start_time": "2023-12-14T16:12:22.331850Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "def create_dataframe(data: pd.DataFrame, img_size: list[int]):\n",
    "    \"\"\" Return a dataframe of pixels of images\n",
    "\n",
    "    Argument:\n",
    "    data: Dataframe with image paths and labels\n",
    "    img_size: pixel sizes\n",
    "    \"\"\"\n",
    "    all_images = []\n",
    "\n",
    "    # Transform each image to pixels array and add to one big array\n",
    "    for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        img = load_img(row['path'], target_size=img_size)\n",
    "        array_img = img_to_array(img, dtype=np.uint8)\n",
    "        array_img_t = array_img.flatten()\n",
    "        all_images.append(array_img_t)\n",
    "\n",
    "    # Create a dataframe from pixels array\n",
    "    column_names = [f'pixel{num}' for num in range(len(all_images[0]))]\n",
    "    df = pd.DataFrame(all_images, columns=column_names)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:12:22.344433Z",
     "start_time": "2023-12-14T16:12:22.337649Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:14<00:00, 691.24it/s]\n"
     ]
    }
   ],
   "source": [
    "X = create_dataframe(labels, img_size)\n",
    "#len(X)\n",
    "#X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:02.351792Z",
     "start_time": "2023-12-14T16:12:22.339384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "0         boston_bull\n1               dingo\n2            pekinese\n3            bluetick\n4    golden_retriever\nName: breed, dtype: object"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = labels.breed\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:02.355334Z",
     "start_time": "2023-12-14T16:19:02.353507Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "120"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:02.362517Z",
     "start_time": "2023-12-14T16:19:02.360032Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "# Process the labels for CNN also\n",
    "le = LabelBinarizer()\n",
    "y_ohe = le.fit_transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:02.413778Z",
     "start_time": "2023-12-14T16:19:02.376864Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8177, 12288)\n",
      "(2045, 12288)\n"
     ]
    }
   ],
   "source": [
    "X_train_dog, X_test_dog, y_train_dog, y_test_dog = train_test_split(X, y_ohe, test_size=0.2, random_state=42)\n",
    "print(X_train_dog.shape)\n",
    "print(X_test_dog.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:02.665042Z",
     "start_time": "2023-12-14T16:19:02.413934Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Traditional machine learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "# Initially testing if KNN is slow in training\n",
    "X_train_sample = X_train_dog[:1000]\n",
    "y_train_sample = y_train_dog[:1000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:02.667305Z",
     "start_time": "2023-12-14T16:19:02.665779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier(n_neighbors=1)",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_2 = KNeighborsClassifier(n_neighbors=1)\n",
    "#knn_2.fit(X_train_sample, y_train_sample)\n",
    "knn_2.fit(X_train_dog, y_train_dog)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:02.910512Z",
     "start_time": "2023-12-14T16:19:02.670145Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "y_pred_dog = knn_2.predict(X_test_dog.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:08.609056Z",
     "start_time": "2023-12-14T16:19:02.911413Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "0.033251833740831294"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_dog, y_pred_dog)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:08.621173Z",
     "start_time": "2023-12-14T16:19:08.609824Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Comment: As we can clearly see, for the digits task, the KNN performed well but with a much more complex task like dog breed identification, it does not perform well at all."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "def process_images(data: pd.DataFrame, img_size: list[int] = [224, 224]):\n",
    "    \"\"\" Return the pixels array for CNN\n",
    "\n",
    "    Argument:\n",
    "    data: Dataframe with image paths and labels\n",
    "    img_size: pixel sizes\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list to hold pixels\n",
    "    img_arrays = []\n",
    "\n",
    "    # Transform each image into pixels array\n",
    "    for _, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        img = load_img(row.path, target_size=img_size)\n",
    "        img_array = img_to_array(img, dtype=np.uint8)\n",
    "        img_arrays.append(img_array)\n",
    "\n",
    "    # Convert into a numpy array for the CNN\n",
    "    one_img_arr = np.array(img_arrays)\n",
    "    return one_img_arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:08.623857Z",
     "start_time": "2023-12-14T16:19:08.622625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:15<00:00, 676.32it/s]\n"
     ]
    }
   ],
   "source": [
    "X_cnn = process_images(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:24.790594Z",
     "start_time": "2023-12-14T16:19:08.624810Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Comment: With KNN, the pixels size is very important because the higher the size, the longer it takes to convert into array and longer training time. With CNN, it is easier as it can deal with larger pixels size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build from scratch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "X_train_dog_cnn, X_test_dog_cnn, y_train_dog_cnn, y_test_dog_cnn = train_test_split(X_cnn, y_ohe, test_size=.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:19:25.651149Z",
     "start_time": "2023-12-14T16:19:24.792345Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "X_train_dog_cnn = X_train_dog_cnn / 255\n",
    "X_test_dog_cnn = X_test_dog_cnn / 255"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:20:22.896274Z",
     "start_time": "2023-12-14T16:19:25.652349Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3), padding=\"same\"))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model_2.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model_2.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model_2.add(Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model_2.add(Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model_2.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(512, activation=\"relu\"))\n",
    "model_2.add(Dense(y.nunique(), activation=\"softmax\"))\n",
    "model_2.summary()\n",
    "\n",
    "model_2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "model_2.fit(X_train_dog_cnn, y_train_dog_cnn, batch_size=64, epochs=10, validation_data=(X_test_dog_cnn, y_test_dog_cnn))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Comment: Build my own CNN model took a long time, so I try the transfer learning approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transfer learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (3951840141.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[169], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    def get_features(model_name=InceptionV3, model_preprocessor=inception_preprocess, input_size=[224,224,3], data):\u001B[0m\n\u001B[0m                                                                                                              ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "# Credit to the HÜSEYIN CENİK team on kaggle for the following code\n",
    "def get_features(model_name, model_preprocessor, input_size, data: pd.DataFrame):\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = model_preprocessor(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False, input_shape=input_size)(preprocessor)\n",
    "    maxPool = MaxPooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs=input_layer, outputs=maxPool)\n",
    "    feature_maps = feature_extractor.predict(data, verbose=1)\n",
    "    print('Feature maps shape:', feature_maps.shape)\n",
    "    return feature_maps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T17:13:47.375729Z",
     "start_time": "2023-12-14T17:13:47.372843Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### InceptionV3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 366s 1s/step\n",
      "Feature maps shape: (10222, 2, 2, 2048)\n"
     ]
    }
   ],
   "source": [
    "features = get_features(InceptionV3, inception_preprocess, [224, 224, 3], X_cnn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:30:26.437169Z",
     "start_time": "2023-12-14T16:24:07.414313Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(features, y_ohe, test_size=.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:31:55.731092Z",
     "start_time": "2023-12-14T16:31:55.547481Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_22 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 512)               4194816   \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 120)               61560     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4256376 (16.24 MB)\n",
      "Trainable params: 4256376 (16.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Input(X_train_tf.shape[1:]))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(Dense(512, activation=\"relu\"))\n",
    "model_3.add(Dense(y.nunique(), activation=\"softmax\"))\n",
    "\n",
    "model_3.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:31:57.869117Z",
     "start_time": "2023-12-14T16:31:57.739976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "model_3.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:32:00.817415Z",
     "start_time": "2023-12-14T16:32:00.814447Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', min_delta=1, verbose=1, patience=5, restore_best_weights=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:32:02.812835Z",
     "start_time": "2023-12-14T16:32:02.808132Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "128/128 [==============================] - 2s 14ms/step - loss: 2.2822 - accuracy: 0.6006 - val_loss: 1.1810 - val_accuracy: 0.7042\n",
      "Epoch 2/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.7640 - accuracy: 0.7868 - val_loss: 1.1877 - val_accuracy: 0.7076\n",
      "Epoch 3/20\n",
      "128/128 [==============================] - 2s 12ms/step - loss: 0.5111 - accuracy: 0.8477 - val_loss: 1.0251 - val_accuracy: 0.7472\n",
      "Epoch 4/20\n",
      "128/128 [==============================] - 2s 16ms/step - loss: 0.3131 - accuracy: 0.9017 - val_loss: 1.1236 - val_accuracy: 0.7521\n",
      "Epoch 5/20\n",
      "128/128 [==============================] - 2s 12ms/step - loss: 0.2169 - accuracy: 0.9303 - val_loss: 1.1875 - val_accuracy: 0.7477\n",
      "Epoch 6/20\n",
      "128/128 [==============================] - 2s 17ms/step - loss: 0.1512 - accuracy: 0.9481 - val_loss: 1.3017 - val_accuracy: 0.7384\n",
      "Epoch 7/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.1125 - accuracy: 0.9626 - val_loss: 1.2843 - val_accuracy: 0.7472\n",
      "Epoch 8/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.0950 - accuracy: 0.9673 - val_loss: 1.4044 - val_accuracy: 0.7540\n",
      "Epoch 9/20\n",
      "128/128 [==============================] - 1s 11ms/step - loss: 0.0808 - accuracy: 0.9725 - val_loss: 1.3954 - val_accuracy: 0.7535\n",
      "Epoch 10/20\n",
      "128/128 [==============================] - 2s 12ms/step - loss: 0.0664 - accuracy: 0.9785 - val_loss: 1.4743 - val_accuracy: 0.7560\n",
      "Epoch 11/20\n",
      "128/128 [==============================] - 2s 13ms/step - loss: 0.0669 - accuracy: 0.9802 - val_loss: 1.6007 - val_accuracy: 0.7403\n",
      "Epoch 12/20\n",
      "128/128 [==============================] - 2s 15ms/step - loss: 0.1011 - accuracy: 0.9688 - val_loss: 1.6484 - val_accuracy: 0.7218\n",
      "Epoch 13/20\n",
      "128/128 [==============================] - 2s 15ms/step - loss: 0.1617 - accuracy: 0.9499 - val_loss: 1.6721 - val_accuracy: 0.7399\n",
      "Epoch 14/20\n",
      "128/128 [==============================] - 2s 15ms/step - loss: 0.1666 - accuracy: 0.9489 - val_loss: 1.5757 - val_accuracy: 0.7355\n",
      "Epoch 15/20\n",
      "128/128 [==============================] - 2s 13ms/step - loss: 0.1637 - accuracy: 0.9494 - val_loss: 1.7422 - val_accuracy: 0.7325\n",
      "Epoch 16/20\n",
      "128/128 [==============================] - 1s 11ms/step - loss: 0.1155 - accuracy: 0.9628 - val_loss: 1.9276 - val_accuracy: 0.7213\n",
      "Epoch 17/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.1030 - accuracy: 0.9669 - val_loss: 1.9727 - val_accuracy: 0.7262\n",
      "Epoch 18/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.0909 - accuracy: 0.9718 - val_loss: 1.9026 - val_accuracy: 0.7443\n",
      "Epoch 19/20\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.0790 - accuracy: 0.9751 - val_loss: 1.8811 - val_accuracy: 0.7384\n",
      "Epoch 20/20\n",
      "128/128 [==============================] - 1s 11ms/step - loss: 0.0830 - accuracy: 0.9759 - val_loss: 2.0738 - val_accuracy: 0.7203\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x286cd7510>"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train_tf, y_train_tf, batch_size=64, epochs=20, validation_data=(X_test_tf, y_test_tf))#, callbacks=[es])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T16:32:36.925671Z",
     "start_time": "2023-12-14T16:32:04.496721Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Comment: as we can see the accuracy of the new model performs really well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 5/5 [00:00<00:00, 262.59it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_image(image_path, target_size=[224, 224]):\n",
    "\n",
    "    # Load and transform images\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "\n",
    "    return img_array\n",
    "\n",
    "test_path = \"../Assignment 1/dog-breed-identification/test/\"\n",
    "\n",
    "preprocessed_images = []\n",
    "for filename in tqdm(os.listdir(test_path)[:5], desc='Processing images'):\n",
    "    if filename.endswith('.jpg'):\n",
    "        file_path = os.path.join(test_path, filename)\n",
    "        img = load_and_preprocess_image(file_path)\n",
    "        preprocessed_images.append(img)\n",
    "\n",
    "preprocessed_test_images = np.array(preprocessed_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T17:14:37.285737Z",
     "start_time": "2023-12-14T17:14:37.218674Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "breeds = sorted(labels[\"breed\"].unique().tolist())\n",
    "class_to_num = dict(zip(breeds, range(len(breeds))))\n",
    "num_to_class = {v: k for k, v in class_to_num.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T17:25:16.378218Z",
     "start_time": "2023-12-14T17:25:16.372727Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 447ms/step\n",
      "Feature maps shape: (5, 2, 2, 2048)\n",
      "1/1 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_features = get_features(InceptionV3, inception_preprocess, [224, 224, 3], preprocessed_test_images)\n",
    "predicted_test = model_3.predict(test_features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T17:22:23.688002Z",
     "start_time": "2023-12-14T17:22:22.011394Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "data": {
      "text/plain": "array([12, 59, 78, 50, 36])"
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes = np.argmax(predicted_test, axis=1)\n",
    "predicted_classes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T17:22:17.685659Z",
     "start_time": "2023-12-14T17:22:17.679625Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "data": {
      "text/plain": "['black-and-tan_coonhound',\n 'irish_wolfhound',\n 'newfoundland',\n 'gordon_setter',\n 'dhole']"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = [num_to_class[index] for index in predicted_classes]\n",
    "\n",
    "mapping"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T17:25:44.691334Z",
     "start_time": "2023-12-14T17:25:44.683016Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
